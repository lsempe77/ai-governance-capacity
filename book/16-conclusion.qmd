---
title: "Conclusion"
---

## Toward a Living Observatory {#sec-conclusion}

This study set out to answer a simple question: *Do countries have the capacity to implement their AI policies?* The answer, based on 2,216 policies across 70+ jurisdictions, is sobering: **overwhelmingly, no.** The global modal AI policy is aspirational rather than operational, scoring below 2/4 on both implementation capacity and ethics operationalisation.

But the richer finding is how this deficit is distributed. Contrary to the prevailing narrative of a stark North–South governance divide, the income-group gap is both **small** ($d = 0.20$–$0.30$) and **fragile**, vanishing when controlling for text quality. **Within-group inequality dominates** the distribution, with 98–99% of variation occurring among countries within the same income category rather than between income groups. **GDP explains remarkably little** of the variation in governance scores (1.5–3.5%), as evidenced by countries such as Rwanda, Kenya, and Brazil achieving governance quality that many wealthy nations do not. Finally, **policy diffusion operates horizontally** rather than vertically, with countries learning from peers in similar economic circumstances rather than from wealthy exemplars.

### Five Takeaways

*The governance gap is universal.* Every country — wealthy and developing alike — needs to strengthen its AI governance infrastructure, with particular attention to accountability and monitoring mechanisms that enable implementation oversight and course correction.

*GDP is not destiny.* Governance quality emerges from policy choices rather than economic endowments. The efficiency frontier analysis demonstrates that focused effort and institutional design matter more than fiscal capacity alone.

*Ethics is not a luxury good.* GDP has zero effect on ethics scores across all quantiles of the distribution. Developing countries can and do build meaningful ethical governance frameworks, suggesting that ethical commitments are independent of national wealth.

*Measurement matters.* The text quality confound serves as a cautionary reminder for all comparative governance research: what we measure through policy documents may reflect document availability and drafting resources as much as underlying institutional reality.

*Peer learning beats transplantation.* The horizontal diffusion pattern identified in @sec-cap-dynamics supports South–South cooperation and regional learning networks over top-down technical assistance models that assume wealthy countries provide templates for others to follow.

### The Observatory Vision

We envision this work as the foundation for a **living observatory** — a continuously updated dataset that tracks AI governance capacity over time. Such an observatory would enable **annual scoring rounds** to detect trends and convergence patterns, provide **country-level scorecards** offering actionable diagnostics for policymakers, support **benchmarking tools** for international organisations and civil society actors, and establish **research infrastructure** for the growing community of AI governance scholars.

The code, data, and methods are fully open-source at <https://github.com/lsempe77/ai-governance-capacity>, designed for replication and extension.

---

*The question is not whether AI will be governed, but whether it will be governed well. The evidence in this book suggests that the capacity to govern well is neither automatic nor impossible — it is built, one dimension at a time, by countries willing to invest in the institutional infrastructure that turns aspiration into action.*
