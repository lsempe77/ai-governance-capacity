---
title: "Preface"
---

## About This Document {.unnumbered}

This document a systematic, large-scale assessment of AI governance **implementation capacity** — the gap between policy aspiration and institutional readiness. Drawing on the complete OECD.AI Policy Observatory — the most comprehensive global repository of AI governance documents — we analyze 2,216 policy documents spanning 70+ jurisdictions. Using a three-model LLM ensemble to assess each policy, we address a central question that proves more complex than it initially appears:

> *Do countries have the capacity to implement their AI policies, and how does this vary between high-income and developing countries?*

The findings present a more complex picture than conventional narratives about AI governance capacity would suggest.

### Structure {.unnumbered}

The document is organised in three parts:

**Part I — AI Governance Capacity** analyses the five implementation dimensions (Clarity, Resources, Authority, Accountability, Coherence) grounded in Mazmanian–Sabatier implementation theory.

**Part II — AI Ethics Governance** examines the five ethics dimensions (Framework Depth, Rights Protection, Governance Mechanisms, Operationalisation, Inclusion) grounded in Jobin et al., UNESCO, and OECD AI Principles.

**Part III — Cross-Cutting Analysis** explores the two-factor structure linking capacity and ethics, and presents comprehensive robustness checks.

### Key Findings at a Glance {.unnumbered}

The analysis reveals several patterns that challenge conventional assumptions about AI governance capacity. First, our assessment finds that the vast majority of policies in the OECD.AI repository demonstrate low implementation capacity, with most falling below the midpoint of our readiness scale. This indicates that the capacity gap is a universal challenge rather than one confined to developing countries. Second, while an income-group gap appears in the raw data, this gap vanishes when controlling for text quality, raising important questions about measurement versus substantive differences. Third, within-group inequality dominates the distribution of scores: nearly all variation occurs *within* income groups rather than between them, suggesting that national wealth explains remarkably little about governance quality.

Indeed, GDP explains only a small fraction of country-level score variation. Several developing countries — Brazil, Kenya, Rwanda, and Tunisia — consistently outperform their GDP-predicted governance levels, demonstrating that governance capacity is shaped by policy choices rather than economic endowments alone. The temporal analysis shows that ethics scores are converging across income groups, though this convergence is driven by high-income countries declining rather than developing countries improving. Finally, our examination of how policies spread across countries reveals that policy learning occurs overwhelmingly horizontally — peer-to-peer within income groups — rather than through top-down transmission from wealthy to poor countries.

### Replication {.unnumbered}

All code, data, and analysis outputs are available at: <https://github.com/lsempe77/ai-governance-capacity>

