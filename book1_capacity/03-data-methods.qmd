---
title: "Data & Methods"
---

## The OECD.AI Corpus {#sec-data-methods}

### Data Source {#sec-data-source}

I draw on the **OECD.AI Policy Observatory** [@oecdai2024], the most comprehensive international tracker of AI policy initiatives. The Observatory catalogues government actions related to AI (national strategies, legislation, executive orders, guidelines, and programmes) with structured metadata on jurisdiction, year, policy type, target sectors, and responsible organisations. Each entry follows a consistent documentation schema, making it well suited for cross-national comparison.

I scraped the complete Observatory as of January 2026, obtaining **2,216 policy entries** across **70+ jurisdictions** spanning **2017–2025**.

| Metric | Value |
|:---|---:|
| Total policy entries | 2,216 |
| Unique jurisdictions | 70+ |
| Time span | 2017–2025 |
| Policy types | Strategies, laws, guidelines, executive orders, programmes |
| Source | OECD.AI Policy Observatory |

: Corpus overview {#tbl-corpus-overview}

The 70+ jurisdictions include not only major economies but also developing countries in Africa, Asia, and Latin America, providing the geographic diversity needed to examine capacity gaps across income levels.

### Document Retrieval {#sec-retrieval}

The Observatory provides brief descriptions (typically <500 words) and links to source documents, but does not host full texts. I needed the actual policy documents for detailed capacity assessment, so I built a five-strategy cascading retrieval pipeline:

1. Direct download from `source_url` (~60% success)
2. Scraping embedded links from each OECD.AI entry page
3. Internet Archive Wayback Machine for moved/expired URLs
4. DuckDuckGo search with policy title, jurisdiction, and file type restrictions
5. Claude API web search for the most difficult cases

This pipeline achieved ~94% coverage (2,085 documents retrieved). The remaining entries, mostly press releases or brief announcements, were retained as OECD snippets.

### Text Extraction {#sec-extraction}

Policy documents arrive in varied formats: text-based or scanned PDFs, web pages with complex navigation, documents ranging from single pages to hundred-page legislative texts. I used format-specific extraction tools: PyMuPDF (`fitz`) for PDFs, `trafilatura` for HTML content extraction, and OECD snippet text as a fallback.

Each document was classified into three quality tiers by word count:

| Quality Tier | Word Count | N | % | Description |
|:---|:---|---:|---:|:---|
| Good | ≥500 words | 948 | 42.8% | Full analysis possible |
| Thin | 100–499 words | 806 | 36.4% | Usable with caveats |
| Stub | <100 words | 462 | 20.8% | Minimal text only |
| | **Analysis-ready** | **1,754** | **79.2%** | Good + Thin |

: Text quality distribution {#tbl-text-quality}

About 80% of the corpus (1,754 documents) has enough text for reliable analysis. The 462 stubs contribute little analytically but are retained in corpus statistics. Total extracted text: 11.4 million words; median document length: 1,247 words (IQR: 318–4,892).

### Enriched Corpus {#sec-enriched-corpus}

The pipeline produces a unified corpus file (`corpus_enriched.json`) merging OECD metadata with extracted text and quality assessments. Each of the 2,216 entries retains its original OECD metadata (title, jurisdiction, year, URL, policy type, target sectors) plus extracted full text, quality classification, word count, and extraction method.

### Country Metadata {#sec-country-metadata}

To enable cross-national comparison, each jurisdiction was mapped to standardized contextual metadata using World Bank classifications. Income groups follow the World Bank's four-tier system: High Income (HI), Upper Middle Income (UMI), Lower Middle Income (LMI), and Low Income (LI). For analyses focused on the North–South divide, we constructed a binary classification contrasting High Income countries against Developing countries (aggregating UMI, LMI, and LI). Regional classifications employ the World Bank's geographic taxonomy: East Asia & Pacific (EAP), Europe & Central Asia (ECA), Latin America & Caribbean (LAC), Middle East & North Africa (MENA), North America (NAM), South Asia (SA), and Sub-Saharan Africa (SSA). We also incorporated GDP per capita (current US dollars, 2023) as a continuous measure of economic development, enabling analyses that examine governance quality relative to national wealth.

International organisations — including the OECD itself, the European Union, the United Nations, and multilateral development banks — were flagged separately and excluded from country-level analyses where appropriate, as these entities operate under different institutional logics than national governments.

### Sample Composition {#sec-sample}

The final analytical sample reflects the OECD.AI Observatory's coverage, which skews toward high-income countries:

| Income Group | N Policies | % | N Countries |
|:---|---:|---:|---:|
| High Income | 1,700 | 76.7% | ~40 |
| Developing | 397 | 17.9% | ~30 |
| International | 119 | 5.4% | — |
| **Total** | **2,216** | **100%** | **70+** |

: Sample by income group {#tbl-sample-income}

The compositional imbalance is clear: high-income countries account for 77% of policies, developing countries for 18%. This reflects the actual distribution of AI governance activity. Rich countries have simply produced more policies and maintained more accessible archives. I address this imbalance through robustness checks in @sec-robustness, including restriction to well-documented policies and country-level aggregations.

### Analytical Pipeline Overview {#sec-pipeline-overview}

@fig-pipeline shows the full journey from raw OECD.AI metadata to the 120 outputs (figures, tables, statistical tests) in subsequent chapters. The 6,641 LLM API calls represent three model assessments for each of the 2,216 policies across 10 dimensions.

```{mermaid}
%%| label: fig-pipeline
%%| fig-cap: "Analytical pipeline from corpus to results"
%%| fig-width: 8

graph LR
    A[OECD.AI<br/>2,216 entries] --> B[Document<br/>Retrieval<br/>94% coverage]
    B --> C[Text<br/>Extraction<br/>1,754 ready]
    C --> D[LLM Scoring<br/>3-model ensemble<br/>6,641 calls]
    D --> E[20 Analyses<br/>120 outputs]
    
    style A fill:#e1f5fe
    style B fill:#e8f5e9
    style C fill:#fff3e0
    style D fill:#fce4ec
    style E fill:#f3e5f5
```

### Analytical Methods {#sec-analytical-methods}

The chapters that follow use several complementary statistical methods. I overview the core techniques here; model specifications appear in the relevant chapters.

#### Text-to-Data Conversion: LLM Ensemble Scoring

The core method uses frontier LLMs as policy analysts rather than relying on keyword extraction or topic models. Each model reads the full policy document, applies the scoring rubric across all 10 dimensions, and returns structured JSON scores with textual evidence. The three-model ensemble (Claude Sonnet 4, GPT-4o, Gemini Flash 2.0) uses the median score as the final assessment. ICC(2,1) = 0.827 indicates excellent inter-rater reliability; details are in @sec-scoring.

#### Descriptive Analysis

Each analytical chapter begins with descriptive statistics and visual exploration: dimension-specific histograms, ridge plots across groups, radar charts, box-and-violin overlays, and heatmaps.

#### Regression Models

Chapters examining determinants of governance capacity employ four complementary regression approaches. Standard OLS regression establishes baseline relationships between predictors (GDP per capita, policy year, document type, text quality) and capacity scores. Multilevel models with random intercepts for countries account for the nested structure of policies within jurisdictions, correcting for dependency that would otherwise inflate standard errors. Quantile regression examines whether predictors affect low-scoring and high-scoring policies differently, revealing heterogeneous effects across the distribution. Tobit models address the substantial floor effect (27.6% of policies score exactly zero) through left-censoring at zero, correcting the attenuation bias that OLS exhibits when floor effects are present.

#### Inequality Analysis

The inequality chapters employ decomposition techniques to partition total variance into meaningful components. Gini coefficients and Lorenz curves quantify overall inequality in governance scores and visualize concentration. Theil's T index enables exact additive decomposition of total inequality into between-group (high-income vs. developing) and within-group components, revealing how much of the apparent North–South divide reflects genuine group differences versus within-group heterogeneity. Policy portfolio analysis examines breadth (whether countries address all dimensions) versus depth (score levels within covered dimensions), distinguishing coverage gaps from implementation quality.

#### Temporal Analysis

Chapters examining governance dynamics over time use panel data methods to separate within-country trends from between-country differences. First-difference models examine year-to-year changes, removing country fixed effects to focus on temporal evolution. We employ Cohen's d effect sizes to assess the substantive significance of changes over time, complementing statistical significance tests that can be misleading with large samples. Convergence analysis tests whether the gap between income groups is narrowing, widening, or remaining stable, using interaction terms between income group and time trends.

#### Multivariate Methods

Principal component analysis (PCA) examines the latent structure underlying the 10 governance dimensions, testing whether capacity and ethics represent empirically distinct constructs. We report eigenvalues, scree plots, and component loadings to assess dimensionality, applying the Kaiser criterion (eigenvalues > 1) to determine the number of meaningful components. Cronbach's alpha assesses internal consistency of the capacity and ethics subscales, quantifying whether dimensions within each construct reliably measure a coherent latent variable. K-means clustering identifies natural groupings of policies based on their multidimensional profiles, with optimal k determined through silhouette coefficients and stability analysis across bootstrap samples.

#### Hypothesis Testing

I use Welch's t-tests and Mann-Whitney U tests for group comparisons, chi-square tests for categorical associations, and report exact p-values, effect sizes (Cohen's d, Cramér's V), and confidence intervals throughout.

### Reproducibility {#sec-reproducibility}

All code is available at <https://github.com/lsempe77/ai-governance-capacity>. The pipeline uses deterministic document IDs (`MD5(url)[:12]`) for reproducibility. API calls used fixed model identifiers and structured JSON output schemas.

### Use of Large Language Models {#sec-llm-acknowledgment}

LLMs play two roles in this project, and I want to be upfront about both.

**As the analytical instrument:** Claude Sonnet 4, GPT-4o, and Gemini Flash 2.0 are the core measurement tool. They convert policy documents into structured scores. This is the methodology itself, documented in @sec-data-methods and @sec-scoring, with all scores preserved in the public repository.

**As a writing aid:** I used GitHub Copilot and Claude for drafting and editing assistance during manuscript preparation. I reviewed and revised all LLM-generated text; analytical decisions, interpretations, and intellectual contributions are my own.
