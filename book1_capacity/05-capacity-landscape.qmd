---
title: "Capacity Landscape"
---

## The Global Landscape of AI Governance Capacity {#sec-cap-landscape}

With the scoring methodology validated and the corpus assembled, this section turns to the central empirical question: what does the global landscape of AI governance capacity actually look like? The analysis proceeds from aggregate distributions through income-group comparisons to regional and country-level patterns, revealing a governance landscape characterised by pervasive weakness, substantial heterogeneity, and a surprising absence of the North–South divide that conventional wisdom would predict.

### Overall Score Distribution {#sec-cap-distribution}

The aggregate picture reveals the baseline state of AI governance capacity across all 2,216 policies.

![Distribution of capacity dimension scores across 2,216 policies. All five dimensions exhibit strong right skew with floor effects at zero.](../data/analysis/paper1_capacity/fig_distributions.png){#fig-cap-distributions}

The capacity composite averages **0.83/4.00** (SD = 0.77), well below the scale midpoint. However, this mean conceals substantial variation. As @fig-cap-distributions shows, all five dimensions exhibit right skewness, with most policies clustered at or near zero and a smaller tail extending upward. Dimension-level means range from 0.48 (C4 Accountability) to 1.07 (C5 Coherence):

| Dimension | Mean | SD | Median |
|:---|---:|---:|---:|
| C1 Clarity & Specificity | 0.94 | 0.97 | 1.00 |
| C2 Resources & Budget | 0.68 | 0.89 | 0.00 |
| C3 Authority & Enforcement | 1.04 | 1.08 | 1.00 |
| C4 Accountability & M&E | 0.48 | 0.72 | 0.00 |
| C5 Coherence & Coordination | 1.07 | 0.97 | 1.00 |
| **Capacity composite** | **0.83** | **0.77** | **0.60** |

: Capacity dimension descriptive statistics {#tbl-cap-descriptives}

One dimension stands out: **Accountability (C4) is the weakest globally**, averaging just 0.48, less than half of Coherence (C5) at 1.07. Governments are more than twice as likely to specify coordination mechanisms as to establish monitoring and evaluation frameworks. They articulate what they intend to do (Clarity) and how agencies should work together (Coherence) before committing to transparent oversight.

The standard deviations (0.72–1.08) are large, and **27.6% of policies score exactly zero** on the composite. More than a quarter of documents in the Observatory function as announcements rather than operational governance instruments. This floor effect, visible in the median of 0.00 for Resources and Accountability, motivates the Tobit approach in @sec-cap-determinants.

### Income-Group Comparisons {#sec-cap-income}

The standard narrative posits a clear North–South divide: wealthy countries have sophisticated frameworks, developing countries struggle to keep up. The data complicate this story.

![Violin plots comparing capacity score distributions between high-income and developing countries. The overlap between distributions is substantial.](../data/analysis/paper1_capacity/fig_income_violins.png){#fig-cap-income-violins}

@fig-cap-income-violins shows both the gap and its limits. High-income countries average 0.87 (SD 0.77), developing countries 0.65 (SD 0.72). The difference is statistically significant:

| Metric | Value |
|:---|:---|
| HI mean (N = 1,700) | 0.87 |
| Developing mean (N = 397) | 0.65 |
| Welch's $t$ | 5.47 |
| $p$-value | < .001 |
| Cohen's $d$ | **0.30** |
| Mann-Whitney $U$ | 395,388 |

: Income-group capacity comparison {#tbl-cap-income}

Statistically significant, yes (t = 5.47, p < .001). But the Cohen's d of **0.30** is small by conventional standards, and the distributions overlap heavily. Many developing-country policies outscore the high-income median; many high-income policies sit near zero.

However, the critical finding emerges when examining text quality: this gap **vanishes entirely** for well-documented policies (d = 0.04, n.s.; see @sec-robustness). This pattern raises a fundamental methodological question: does the observed gap reflect genuine capacity differences, or systematic variation in documentation practices across income groups?

Several mechanisms could produce weaker documentation without weaker governance. Developing countries may publish policies in national languages not captured by the OECD Observatory's predominantly English-language indexing. Their policy documents may be hosted on government websites with limited archival practices, leading to higher rates of link decay and retrieval failure. Implementation details may reside in subsidiary regulations, ministerial orders, or administrative guidance rather than in the primary strategy document indexed by the OECD. And the OECD Observatory itself may provide thinner descriptions for developing-country policies due to reporting asymmetries. These mechanisms would depress measured scores without reflecting genuine capacity deficits.

This question motivates the analyses in subsequent sections.

**Dimension-level gaps.** The aggregate gap masks dimension-level heterogeneity. If the divide reflected generalized institutional weakness, we would expect uniform gaps across all five dimensions. Instead, the pattern is differentiated:

![Boxplots of capacity scores by income group across all five dimensions.](../data/analysis/paper1_capacity/fig_income_boxplot.png){#fig-cap-income-boxplot}

@fig-cap-income-boxplot visualizes how the income gap varies across dimensions, with the gap most pronounced for Resources and Coherence, and smallest for Accountability. The dimension-level statistics reveal this pattern precisely:

| Dimension | HI Mean | Dev Mean | Diff | $d$ | $p$ |
|:---|---:|---:|---:|---:|:---|
| C1 Clarity | 0.98 | 0.74 | 0.24 | 0.30 | < .001 |
| C2 Resources | 0.70 | 0.43 | 0.27 | **0.32** | < .001 |
| C3 Authority | 1.09 | 0.86 | 0.23 | 0.23 | < .001 |
| C4 Accountability | 0.48 | 0.37 | 0.10 | **0.15** | .005 |
| C5 Coherence | 1.13 | 0.86 | 0.27 | 0.29 | < .001 |

: Dimension-level income gaps {#tbl-cap-dim-gaps}

The gap is largest in **Resources (C2)** (d = 0.32) and smallest in **Accountability (C4)** (d = 0.15), confirming hypothesis H3. The logic tracks: specifying budgets and staffing requires fiscal resources that correlate with wealth. Designing monitoring frameworks, by contrast, is primarily a policy design choice, and developing countries could establish reporting requirements and oversight bodies with minimal fiscal commitment.

There is an irony here: both income groups underperform on accountability (0.48 for HI, 0.37 for developing). The reluctance to create transparent oversight mechanisms apparently transcends wealth. Accountability frameworks create political risks by enabling external assessment of implementation failures, a concern that affects all governments.

### Regional Patterns {#sec-cap-regional}

Income groups are blunt instruments. "Developing" lumps together Latin American countries with sophisticated regulatory traditions, South Asian nations with large tech sectors but limited governance infrastructure, and Sub-Saharan African countries with nascent AI policy ecosystems. Regional analysis provides finer grain.

![Heatmap of mean capacity scores by region and dimension. North America and Europe & Central Asia lead; Sub-Saharan Africa and South Asia trail.](../data/analysis/paper1_capacity/fig_region_heatmap.png){#fig-cap-region-heatmap}

@fig-cap-region-heatmap shows substantial regional variation that does not map neatly onto income. **North America** leads across all dimensions, driven by the US and Canada. **Europe & Central Asia** has the broadest dimensional coverage, especially on Coherence (C5), reflecting the EU's multilevel coordination infrastructure.

More interesting are the developing regions that punch above their weight. **Latin America** scores above its income-group average on multiple dimensions, with particular strength in Authority (C3). Brazil, Colombia, and Argentina have adopted binding AI legislation with real enforcement teeth. This likely reflects the region's longstanding tradition of codified law (civil law systems), strong constitutional courts, and established data protection authorities—institutional infrastructure that predates AI governance and provides ready-made channels for algorithmic regulation. The Inter-American Development Bank and regional forums like the Red Iberoamericana have also facilitated policy coordination across the region.

**Sub-Saharan Africa**, while scoring lowest overall, shows surprising strength in Authority: Kenya, Rwanda, and South Africa have enacted AI-specific legislation with compliance mechanisms that exceed what many wealthy countries have managed. These countries benefit from institutional investments in digital governance—Kenya's data protection framework, Rwanda's ICT-driven development strategy, South Africa's constitutional rights infrastructure—that provide foundations for AI-specific regulation. The African Union's AI strategy has also created a continental reference point, though adoption remains uneven.

**East Asia & Pacific** presents a mixed picture: high-performing jurisdictions like Singapore, Japan, and South Korea coexist with countries showing minimal AI governance activity. The region's diversity—spanning high-income technology leaders, rapidly industrialising economies, and small island states—makes regional averages particularly uninformative.

**MENA** and **South Asia** trail on most dimensions, reflecting later entry into AI governance (median first adoption in 2020–2021) rather than inherently weaker institutional capacity. The UAE and Saudi Arabia are notable exceptions in MENA, with comprehensive strategies driven by national economic diversification agendas.

Governance capacity reflects institutional and political factors well beyond simple wealth accumulation.

### Policy-Type Variation {#sec-cap-policy-type}

Not all policy documents carry the same implementation obligations. National strategies articulate visions; binding regulations establish legal requirements; ethics guidelines provide normative frameworks. These functional differences mean capacity scores should vary by type. This reflects the different purposes documents serve rather than genuine capacity differences across jurisdictions.

![Capacity scores by policy type. Binding regulations score highest; guidelines and principles score lowest.](../data/analysis/paper1_capacity/fig_policy_type.png){#fig-cap-policy-type}

As @fig-cap-policy-type confirms, **binding regulation** scores highest. Laws must specify enforcement mechanisms, responsible agencies, and monitoring procedures to be judicially enforceable. **National strategies** sit in the middle, strong on Clarity and Coherence but weaker on Resources and Authority (which strategies typically leave to implementing legislation). **Guidelines and principles** score lowest, reflecting their aspirational character. Ethics guidelines list desirable AI properties without specifying who implements them, how compliance is monitored, or what resources are allocated.

The pattern validates the measurement approach: scores reflect document content appropriate to policy type. It also means that jurisdictions relying on voluntary guidelines will systematically score lower than those with binding legislation, even if the voluntary approach works in practice. Subsequent analyses control for policy type accordingly.

### Country Rankings and Correlation Structure {#sec-cap-rankings}

Which countries have the strongest AI governance capacity? Rankings compress the multidimensional framework into a single scale, losing nuance but gaining interpretive clarity. They reflect both the number of policies and their average quality. The top-scoring jurisdictions combine large portfolios with consistently high individual scores:

| Rank | Jurisdiction | Mean Score | Income | N Policies |
|:---|:---|---:|:---|---:|
| 1 | European Union | 1.42 | HI | 60 |
| 2 | Canada | 1.38 | HI | 15 |
| 3 | United Kingdom | 1.32 | HI | 72 |
| 4 | United States | 1.28 | HI | 84 |
| 5 | Colombia | 1.21 | UMI | 8 |

: Top 5 jurisdictions by capacity score {#tbl-cap-top5}

The top four are unsurprising: the **EU** (1.42) leads on the strength of the AI Act and its complementary policies; **Canada** (1.38) and the **UK** (1.32) show that smaller portfolios can achieve high quality; the **US** (1.28) ranks fourth because its massive 84-document portfolio includes substantial variation across federal agencies and states.

The fifth slot is more interesting. **Colombia** (1.21), an upper-middle-income country, outperforms dozens of wealthy nations with just eight focused, well-designed policies. This is a preview of a pattern explored in @sec-cap-dynamics: several developing countries, including Brazil (consistently top 10) and Kenya (above many European countries), achieve strong capacity through strategic design rather than resource abundance.

**Correlation structure.** The five capacity dimensions are positively correlated (r = 0.45 to 0.75) but maintain sufficient discriminant validity to justify separate measurement. A common governance quality factor accounts for ~66% of variance in PCA, meaning policies that score high on one dimension tend to score high on others. However, the residual independence is substantively important: a policy can score high on Clarity (well-defined objectives) while scoring low on Resources (no budget), or achieve strong Coherence (coordination) despite weak Accountability (no monitoring). The strongest links—Authority with Coherence (r = 0.75) and Clarity with Authority (r = 0.70)—make structural sense: policies with legal mandates more readily establish coordination mechanisms.

![Correlation matrix across the five capacity dimensions.](../data/analysis/paper1_capacity/fig_correlations.png){#fig-cap-correlations}
